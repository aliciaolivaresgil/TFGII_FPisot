{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototipo de prompting para comprender el uso de LLM's y su interacción.\n",
    "## Trabajo Fin de Grado - Universidad de Burgos - Ingeniería Informática\n",
    "### Autor: Fernando Pisot Serrano fps1001@alu.ubu.es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt simple\n",
    "Se va a usar OpenAI \n",
    "Prompt: información que le damos al LLM. \n",
    "Contexto: es la 'memoria' del "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instalación de Bibliotecas**\n",
    "\n",
    "Ejecuta la siguiente celda para instalar las bibliotecas necesarias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openai # Para instalar OpenAI si no está instalado.\n",
    "%pip install transformers torch # Para instalar Transformers y Torch si no están instalados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=DELOjYAtbkg&t=977s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargar un Modelo y Generar Texto**\n",
    "\n",
    "En esta sección, cargaremos un modelo de lenguaje y generaremos texto a partir de un prompt dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Cargar un pipeline de generación de texto\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-2.7B')\n",
    "\n",
    "# Generar texto\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "print(generated_text[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
